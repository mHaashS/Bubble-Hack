import os
import cv2
import torch
import numpy as np
import logging
from detectron2.config import get_cfg
from detectron2.engine import DefaultPredictor
from detectron2 import model_zoo

# Configuration du logging
logger = logging.getLogger(__name__)

# === CONFIGURATION DES CHEMINS ===
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_DIR = os.path.abspath(os.path.join(SCRIPT_DIR, ".."))

print(f"üîß SCRIPT_DIR: {SCRIPT_DIR}")
print(f"üîß PROJECT_DIR: {PROJECT_DIR}")

cfg = get_cfg()
cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))

# T√©l√©charger le mod√®le depuis Hugging Face si n√©cessaire
def get_model_path():
    """Obtenir le chemin du mod√®le, le t√©l√©charger depuis Hugging Face si n√©cessaire"""
    model_path = os.path.join(PROJECT_DIR, "models_ai", "model_final.pth")
    
    if os.path.exists(model_path):
        print(f"‚úÖ Mod√®le local trouv√©: {model_path}")
        return model_path
    
    print("üîß Mod√®le local non trouv√©, t√©l√©chargement depuis Hugging Face...")
    try:
        from huggingface_hub import hf_hub_download
        import time
        
        # Retry avec timeout
        for attempt in range(3):
            try:
                print(f"üîß Tentative {attempt + 1}/3...")
                model_path = hf_hub_download(
                    repo_id="HaashS/modelev1",
                    filename="model_final.pth",
                    local_dir=os.path.join(PROJECT_DIR, "models_ai"),
                    local_files_only=False,
                    resume_download=True
                )
                print(f"‚úÖ Mod√®le t√©l√©charg√© depuis Hugging Face: {model_path}")
                return model_path
            except Exception as e:
                print(f"‚ö†Ô∏è  Tentative {attempt + 1} √©chou√©e: {e}")
                if attempt < 2:
                    print("üîÑ Nouvelle tentative dans 5 secondes...")
                    time.sleep(5)
                else:
                    raise e
    except Exception as e:
        print(f"‚ùå Erreur t√©l√©chargement Hugging Face apr√®s 3 tentatives: {e}")
        raise Exception(f"Impossible de t√©l√©charger le mod√®le depuis Hugging Face: {e}")

# Obtenir le chemin du mod√®le
model_path = get_model_path()
print(f"üîß Chemin du mod√®le: {model_path}")

# V√©rifier la taille du fichier
file_size = os.path.getsize(model_path)
print(f"üîß Taille du fichier: {file_size} bytes")

# V√©rifier si le fichier est valide
try:
    import torch
    test_model = torch.load(model_path, map_location='cpu', weights_only=False)
    print(f"‚úÖ Mod√®le valide (taille: {file_size} bytes)")
    cfg.MODEL.WEIGHTS = model_path
    logger.info(f"Chargement du mod√®le personnalis√©: {model_path}")
except Exception as e:
    logger.error(f"Erreur lors de la validation du mod√®le personnalis√©: {e}")
    print(f"‚ùå Erreur validation mod√®le personnalis√©: {e}")
    raise Exception(f"Impossible de charger le mod√®le personnalis√©: {e}")

cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3  # bubble, floating_text, narration_box
cfg.MODEL.DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

print(f"üîß Device utilis√©: {cfg.MODEL.DEVICE}")
print(f"üîß CUDA disponible: {torch.cuda.is_available()}")

# Chargement paresseux du mod√®le
predictor = None

def load_predictor():
    """Charger le mod√®le Detectron2 de mani√®re paresseuse"""
    global predictor
    if predictor is not None:
        print("‚úÖ Mod√®le d√©j√† charg√©, r√©utilisation")
        return predictor
    
    try:
        print("üîß Tentative de chargement du mod√®le Detectron2...")
        print(f"üîß Configuration: {cfg.MODEL.WEIGHTS}")
        print(f"üîß Device: {cfg.MODEL.DEVICE}")
        print(f"üîß Classes: {cfg.MODEL.ROI_HEADS.NUM_CLASSES}")
        
        # V√©rifier la m√©moire disponible
        import psutil
        memory = psutil.virtual_memory()
        print(f"üîß M√©moire disponible: {memory.available / 1024**3:.1f} GB")
        print(f"üîß M√©moire utilis√©e: {memory.percent}%")
        
        predictor = DefaultPredictor(cfg)
        logger.info("Mod√®le Detectron2 charg√© avec succ√®s")
        print("‚úÖ Mod√®le Detectron2 charg√© avec succ√®s")
        print(f"üîß Type du predictor: {type(predictor)}")
        
        # Test rapide du mod√®le
        print("üîß Test du mod√®le avec une image factice...")
        import numpy as np
        test_image = np.zeros((100, 100, 3), dtype=np.uint8)
        test_output = predictor(test_image)
        print(f"‚úÖ Test du mod√®le r√©ussi: {len(test_output['instances'])} d√©tections")
        
        return predictor
    except Exception as e:
        logger.error(f"Erreur lors du chargement du mod√®le: {e}")
        print(f"‚ùå Erreur chargement mod√®le: {e}")
        import traceback
        traceback.print_exc()
        raise Exception(f"Impossible de charger le mod√®le Detectron2: {e}")

# === PARAM√àTRES DE NETTOYAGE ===
FILL_COLOR = (255, 255, 255)  # Blanc

CLASS_NAMES = {
    0: "bubble",
    1: "floating_text",
    2: "narration_box"
}

def clean_bubbles(image, outputs):
    """
    Nettoie les bulles de texte d√©tect√©es dans l'image
    """
    # Autoriser le nettoyage m√™me si le mod√®le n'est pas charg√© lorsque des sorties (outputs) sont fournies
    # Le mod√®le est uniquement n√©cessaire pour effectuer la d√©tection, pas pour appliquer des masques d√©j√† fournis.
    if outputs is None:
        print("‚ùå Erreur: Aucune d√©tection fournie (outputs=None)")
        return image  # Retourner l'image originale si aucune d√©tection n'est possible
    
    try:
        # V√©rifier si outputs est valide
        if outputs is None:
            print("‚ùå Erreur: Aucune d√©tection effectu√©e")
            return image
        
        # Le reste du code reste identique
        result = image.copy()
        height, width = image.shape[:2]
        
        # Cr√©er un masque pour l'inpainting (utilis√© pour "floating_text")
        inpaint_mask = np.zeros((height, width), dtype=np.uint8)
        
        # Traiter chaque instance d√©tect√©e (supporte dict ou objet MockOutputs)
        instances = None
        if isinstance(outputs, dict) and "instances" in outputs:
            instances = outputs["instances"]
        elif hasattr(outputs, "instances"):
            instances = outputs.instances
        
        if instances is not None:
            # Calculer le nombre d'instances de mani√®re robuste (compat MockInstances)
            try:
                num_instances = len(instances)
            except TypeError:
                # Fallback si l'objet n'impl√©mente pas __len__ (MockInstances)
                if hasattr(instances, "pred_masks") and hasattr(instances.pred_masks, "shape"):
                    num_instances = int(instances.pred_masks.shape[0])
                else:
                    num_instances = 0

            if num_instances == 0:
                print("‚ÑπÔ∏è  Aucune bulle d√©tect√©e dans l'image")
                return result
            
            print(f"üîç Traitement de {num_instances} bulles d√©tect√©es")
            
            for i in range(num_instances):
                # R√©cup√©rer le masque de l'instance
                mask = instances.pred_masks[i].cpu().numpy().astype(np.uint8)
                # Classe si disponible (0: bubble, 1: floating_text, 2: narration_box)
                class_id = None
                if hasattr(instances, "pred_classes"):
                    try:
                        class_id = int(instances.pred_classes[i].item())
                    except Exception:
                        class_id = 0
                else:
                    class_id = 0
                
                # Redimensionner le masque √† la taille de l'image si n√©cessaire
                if mask.shape != (height, width):
                    mask = cv2.resize(mask, (width, height), interpolation=cv2.INTER_NEAREST)
                
                # Si c'est une bulle/bo√Æte de narration ‚Üí remplissage blanc OPAQUE (avec bord doux)
                if class_id in (0, 2):
                    mask255 = (mask > 0).astype(np.uint8) * 255
                    # Cr√©er une zone int√©rieure √©rod√©e pour garantir un blanc 100% sans fuite de pixels
                    kernel = np.ones((3, 3), np.uint8)
                    eroded = cv2.erode(mask255, kernel, iterations=1)
                    # Bord = masque - int√©rieur
                    border = cv2.subtract(mask255, eroded)
                    # Remplir en blanc l'int√©rieur (opaque)
                    result[eroded > 0] = FILL_COLOR
                    # Appliquer un l√©ger feather uniquement sur le bord pour √©viter une coupure nette
                    if np.any(border):
                        soft = cv2.GaussianBlur(border, (5, 5), 0)
                        soft = soft.astype(np.float32) / 255.0
                        white = np.full_like(result, FILL_COLOR, dtype=np.uint8)
                        for c in range(3):
                            result[:, :, c] = (
                                soft * white[:, :, c] + (1.0 - soft) * result[:, :, c]
                            ).astype(np.uint8)
                else:
                    # Texte flottant ‚Üí inpainting local
                    inpaint_mask = cv2.bitwise_or(inpaint_mask, mask)
        
        # Appliquer l'inpainting si des bulles ont √©t√© d√©tect√©es
        if np.any(inpaint_mask):
            print("üé® Application de l'inpainting...")
            # Dilater l√©g√®rement le masque pour couvrir les contours du texte
            kernel = np.ones((3, 3), np.uint8)
            dilated = cv2.dilate(inpaint_mask, kernel, iterations=1)
            # Rayon augment√© pour √©viter les artefacts
            result = cv2.inpaint(result, dilated, inpaintRadius=5, flags=cv2.INPAINT_TELEA)
            print("‚úÖ Inpainting termin√©")
        else:
            print("‚ÑπÔ∏è  Aucune bulle √† nettoyer")
        
        return result
        
    except Exception as e:
        print(f"‚ùå Erreur lors du nettoyage: {e}")
        import traceback
        traceback.print_exc()
        return image  # Retourner l'image originale en cas d'erreur 